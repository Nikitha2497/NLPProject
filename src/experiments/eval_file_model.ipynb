{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypet5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtype_env\u001b[39;00m \u001b[39mimport\u001b[39;00m AccuracyMetric\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypet5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     PickleCache,\n\u001b[1;32m     17\u001b[0m     assert_eq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     write_file,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypet5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualization\u001b[39;00m \u001b[39mimport\u001b[39;00m string_to_html\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtermcolor\u001b[39;00m \u001b[39mimport\u001b[39;00m colored\n\u001b[1;32m     34\u001b[0m os\u001b[39m.\u001b[39mchdir(proj_root())\n",
      "File \u001b[0;32m~/Desktop/sem4/NLP/Final/TypeT5/src/typet5/visualization.py:367\u001b[0m\n\u001b[1;32m    363\u001b[0m         titles \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mR\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dicts))]\n\u001b[1;32m    364\u001b[0m     \u001b[39mreturn\u001b[39;00m visualize_sequence_tabs(tabs, titles\u001b[39m=\u001b[39mtitles)\n\u001b[0;32m--> 367\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m    370\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix_top_k\u001b[39m(y_preds, y_true, k):\n\u001b[1;32m    371\u001b[0m     labels_counts \u001b[39m=\u001b[39m Counter(y_true)\u001b[39m.\u001b[39mmost_common(k)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from typet5.data import get_tk_dataset_name\n",
    "from typet5.function_dataset import data_project_from_dir\n",
    "from typet5.model import ModelWrapper\n",
    "from typet5.train import TrainingConfig, PreprocessArgs\n",
    "from typet5.type_env import AccuracyMetric\n",
    "from typet5.utils import (\n",
    "    PickleCache,\n",
    "    assert_eq,\n",
    "    get_dataroot,\n",
    "    get_dataset_dir,\n",
    "    get_eval_dir,\n",
    "    get_gpu_id,\n",
    "    get_model_dir,\n",
    "    pickle_dump,\n",
    "    pmap,\n",
    "    pretty_print_dict,\n",
    "    pretty_show_dict,\n",
    "    proj_root,\n",
    "    run_long_task,\n",
    "    write_file,\n",
    ")\n",
    "from typet5.visualization import string_to_html\n",
    "from termcolor import colored\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "\n",
    "def wandb_string(s: str):\n",
    "    return wandb.Html(string_to_html(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU_ID not set, using: 1\n",
      "\u001b[32mUse GPU: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# experiment configurations\n",
    "quicktest = False\n",
    "\n",
    "gpu_id = get_gpu_id(1)\n",
    "# model_name = \"model-v6--TrainingConfig(func_only=False, left_margin=2048, preamble_size=800, right_margin=1536)\"\n",
    "model_name = \"model-v6--TrainingConfig(func_only=False, imports_in_preamble=False, stub_in_preamble=False, left_margin=2048, right_margin=1536)\"\n",
    "pre_args = PreprocessArgs(imports_in_preamble=False, stub_in_preamble=False)\n",
    "dataset_name = \"ManyTypes4Py\"\n",
    "# dataset_name = \"InferTypes4Py\"\n",
    "# dataset_name = \"SPOT-src\"\n",
    "experiment_name = dataset_name + \": \" + model_name\n",
    "\n",
    "print(colored(f\"Use GPU: {gpu_id}\", \"green\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TokenizedSrcSets:  /mnt/nas/jiayi/SPOT/TokenizedSrcSets/ManyTypes4Py-v5-PreprocessArgs(imports_in_preamble=False, stub_in_preamble=False)\n",
      "254M\t/mnt/nas/jiayi/SPOT/TokenizedSrcSets/ManyTypes4Py-v5-PreprocessArgs(imports_in_preamble=False, stub_in_preamble=False)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "from typet5.data import load_tokenized_srcsets, create_tokenized_srcsets\n",
    "\n",
    "sdata_name = get_tk_dataset_name(dataset_name, pre_args, func_only=False)\n",
    "sdata_path = get_dataroot() / \"TokenizedSrcSets\" / sdata_name\n",
    "recreate=False\n",
    "if recreate or not sdata_path.exists():\n",
    "    create_tokenized_srcsets(\n",
    "        dataset_name,\n",
    "        sdata_path,\n",
    "        func_only=False,\n",
    "        pre_args=pre_args,\n",
    "    )\n",
    "tk_dataset = load_tokenized_srcsets(\n",
    "    sdata_path,\n",
    "    quicktest=quicktest,\n",
    "    sets_to_load=[\"test\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "from typet5.function_decoding import (\n",
    "    DecodingOrders,\n",
    "    EvalResult,\n",
    "    PreprocessArgs,\n",
    "    RolloutCtx,\n",
    ")\n",
    "from typet5.function_dataset import sigmap_from_file_predictions\n",
    "from typet5.static_analysis import SignatureErrorAnalysis\n",
    "\n",
    "# load model\n",
    "model = ModelWrapper.from_pretrained(get_model_dir() / model_name)\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "ctx_args = model.args.ctx_args\n",
    "model.args.sampling_max_tokens = ctx_args.ctx_size\n",
    "model.args.do_sample = False\n",
    "model.args.num_beams = 10\n",
    "model.args.tokens_per_type = 16\n",
    "\n",
    "eval_cache = PickleCache(get_eval_dir(dataset_name, model_name) / f\"{pre_args}\")\n",
    "# eval_cache.clear()\n",
    "pre_r = eval_cache.cached(\n",
    "    \"DatasetPredResult.pkl\",\n",
    "    lambda: model.eval_on_dataset(tk_dataset[\"test\"]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test projects: 100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies on all types:\n",
      "header:  ['full.all', 'calibrated.all', 'calibrated.simple', 'calibrated.complex', 'base.all']\n",
      "67.07 & 67.47 & 72.12 & 44.05 & 73.44\n",
      "Accuracies on common types:\n",
      "header:  ['full.all', 'calibrated.all', 'calibrated.simple', 'calibrated.complex', 'base.all']\n",
      "76.74 & 78.04 & 82.43 & 53.03 & 82.44\n",
      "Accuracies on rare types:\n",
      "header:  ['full.all', 'calibrated.all', 'calibrated.simple', 'calibrated.complex', 'base.all']\n",
      "49.47 & 52.95 & 57.28 & 34.26 & 57.65\n",
      "full_acc:\n",
      "   full_acc: 67.07% (count=15.7k)\n",
      "   full_acc_by_cat:\n",
      "      FuncArg: 62.00% (count=8.0k)\n",
      "      FuncReturn: 77.89% (count=5.8k)\n",
      "      ClassAtribute: 55.36% (count=1.8k)\n",
      "      GlobalVar: 63.55% (count=107)\n",
      "   full_acc_by_simple:\n",
      "      complex: 41.80% (count=3.3k)\n",
      "      simple: 73.71% (count=12.4k)\n",
      "   full_acc_label_size: 1.4194\n",
      "   full_acc_pred_size: 1.4107\n",
      "   full_acc_ignored_labels: 0\n",
      "   n_missing_types: 53\n",
      "full_acc_common:\n",
      "   full_acc_common: 76.74% (count=10.1k)\n",
      "   full_acc_common_by_cat:\n",
      "      FuncArg: 76.04% (count=5.3k)\n",
      "      FuncReturn: 76.74% (count=3.8k)\n",
      "      ClassAtribute: 79.57% (count=984)\n",
      "      GlobalVar: 88.10% (count=84)\n",
      "   full_acc_common_by_simple:\n",
      "      complex: 48.52% (count=1.8k)\n",
      "      simple: 82.65% (count=8.4k)\n",
      "   full_acc_common_label_size: 1.3693\n",
      "   full_acc_common_pred_size: 1.3379\n",
      "   full_acc_common_ignored_labels: 5569\n",
      "   n_missing_types: 53\n",
      "full_acc_rare:\n",
      "   full_acc_rare: 49.47% (count=5.6k)\n",
      "   full_acc_rare_by_cat:\n",
      "      FuncArg: 51.05% (count=3.2k)\n",
      "      FuncReturn: 48.03% (count=2.0k)\n",
      "      ClassAtribute: 44.10% (count=356)\n",
      "      GlobalVar: 41.67% (count=36)\n",
      "   full_acc_rare_by_simple:\n",
      "      complex: 34.04% (count=1.5k)\n",
      "      simple: 55.24% (count=4.1k)\n",
      "   full_acc_rare_label_size: 1.5103\n",
      "   full_acc_rare_pred_size: 1.543\n",
      "   full_acc_rare_ignored_labels: 10129\n",
      "   n_missing_types: 53\n",
      "acc:\n",
      "   acc: 67.47% (count=13.2k)\n",
      "   acc_by_cat:\n",
      "      FuncArg: 66.28% (count=6.7k)\n",
      "      FuncReturn: 68.91% (count=4.9k)\n",
      "      ClassAtribute: 68.28% (count=1.5k)\n",
      "      GlobalVar: 63.64% (count=99)\n",
      "   acc_by_simple:\n",
      "      complex: 44.05% (count=2.2k)\n",
      "      simple: 72.12% (count=11.0k)\n",
      "   acc_label_size: 1.3155\n",
      "   acc_pred_size: 1.2971\n",
      "   acc_ignored_labels: 2521\n",
      "   n_missing_types: 53\n",
      "acc_common:\n",
      "   acc_common: 78.04% (count=7.6k)\n",
      "   acc_common_by_cat:\n",
      "      FuncArg: 77.28% (count=4.0k)\n",
      "      FuncReturn: 78.69% (count=2.7k)\n",
      "      ClassAtribute: 80.51% (count=816)\n",
      "      GlobalVar: 64.91% (count=57)\n",
      "   acc_common_by_simple:\n",
      "      complex: 53.03% (count=1.1k)\n",
      "      simple: 82.43% (count=6.5k)\n",
      "   acc_common_label_size: 1.2978\n",
      "   acc_common_pred_size: 1.2665\n",
      "   acc_common_ignored_labels: 8072\n",
      "   n_missing_types: 53\n",
      "acc_rare:\n",
      "   acc_rare: 52.95% (count=5.6k)\n",
      "   acc_rare_by_cat:\n",
      "      FuncArg: 55.36% (count=3.2k)\n",
      "      FuncReturn: 50.94% (count=2.0k)\n",
      "      ClassAtribute: 43.26% (count=356)\n",
      "      GlobalVar: 44.44% (count=36)\n",
      "   acc_rare_by_simple:\n",
      "      complex: 34.26% (count=1.0k)\n",
      "      simple: 57.28% (count=4.5k)\n",
      "   acc_rare_label_size: 1.3399\n",
      "   acc_rare_pred_size: 1.3392\n",
      "   acc_rare_ignored_labels: 10147\n",
      "   n_missing_types: 53\n",
      "base_acc:\n",
      "   base_acc: 73.44% (count=13.2k)\n",
      "   base_acc_by_cat:\n",
      "      FuncArg: 72.19% (count=6.7k)\n",
      "      FuncReturn: 74.45% (count=4.9k)\n",
      "      ClassAtribute: 75.77% (count=1.5k)\n",
      "      GlobalVar: 72.73% (count=99)\n",
      "   base_acc_ignored_labels: 2521\n",
      "   n_missing_types: 53\n",
      "base_acc_common:\n",
      "   base_acc_common: 82.44% (count=8.4k)\n",
      "   base_acc_common_by_cat:\n",
      "      FuncArg: 82.34% (count=4.4k)\n",
      "      FuncReturn: 82.62% (count=3.1k)\n",
      "      ClassAtribute: 82.96% (count=886)\n",
      "      GlobalVar: 73.02% (count=63)\n",
      "   base_acc_common_ignored_labels: 7305\n",
      "   n_missing_types: 53\n",
      "base_acc_rare:\n",
      "   base_acc_rare: 57.65% (count=4.8k)\n",
      "   base_acc_rare_by_cat:\n",
      "      FuncArg: 58.01% (count=2.8k)\n",
      "      FuncReturn: 55.16% (count=1.6k)\n",
      "      ClassAtribute: 65.96% (count=332)\n",
      "      GlobalVar: 67.74% (count=31)\n",
      "   base_acc_rare_ignored_labels: 10914\n",
      "   n_missing_types: 53\n"
     ]
    }
   ],
   "source": [
    "repos_dir = get_dataset_dir(dataset_name) / \"repos\" / \"test\"\n",
    "test_repo_paths = [f for f in repos_dir.iterdir() if f.is_dir()]\n",
    "test_projects = pmap(\n",
    "    data_project_from_dir,\n",
    "    test_repo_paths,\n",
    "    desc=\"Loading test projects\",\n",
    ")\n",
    "assert len(test_projects) > 0\n",
    "\n",
    "common_names = ModelWrapper.load_common_type_names(get_model_dir() / model_name)\n",
    "pred_map, label_map = sigmap_from_file_predictions(pre_r, test_projects, repos_dir)\n",
    "accs = {\n",
    "    m.name: SignatureErrorAnalysis(pred_map, label_map, m).accuracies\n",
    "    for m in AccuracyMetric.default_metrics(common_names)\n",
    "}\n",
    "\n",
    "from typet5.experiments.typet5 import accs_as_table_row\n",
    "accs_as_table_row(accs)\n",
    "pretty_print_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting: 100%|██████████| 1851/1851 [00:18<00:00, 100.04it/s]\n",
      "Computing accuracies: 100%|██████████| 1851/1851 [00:00<00:00, 9748.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from typet5.utils import decode_tokens, Path\n",
    "from typet5.visualization import export_preds_on_code\n",
    "\n",
    "export_to = Path(f\"caches/model_predictions/eval_file_model/{dataset_name}\")\n",
    "export_preds_on_code(pre_r.chunks, pre_r.predictions, export_to, AccuracyMetric(common_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
