{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "\n",
    "from typet5.model import ModelWrapper\n",
    "from typet5.train import PreprocessArgs\n",
    "from typet5.utils import *\n",
    "from typet5.function_decoding import (\n",
    "    RolloutCtx,\n",
    "    PreprocessArgs,\n",
    "    DecodingOrders,\n",
    "    AccuracyMetric,\n",
    ")\n",
    "from typet5.static_analysis import PythonProject\n",
    "\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8491b018955f4e0ab9d7f0dd2b55a207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# download or load the model\n",
    "# wrapper = ModelWrapper.load_from_hub(\"MrVPlusOne/TypeT5-v7\")\n",
    "# device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# wrapper.to(device)\n",
    "# print(\"model loaded\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    " \n",
    "model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "wrapper = ModelWrapper.load_from_hub(\"MrVPlusOne/TypeT5-v7\")\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the rollout parameters\n",
    "rctx = RolloutCtx(model=wrapper)\n",
    "pre_args = PreprocessArgs()\n",
    "# we use the double-traversal decoding order, where the model can make corrections \n",
    "# to its previous predictions in the second pass\n",
    "decode_order = DecodingOrders.DoubleTraversal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_code_2/fib: (n: int) -> int\n",
      "ex_code_2/foo: (bar: int) -> int\n",
      "ex_code_2/Bar.x: int\n",
      "ex_code_2/Bar.y: int\n",
      "ex_code_2/Bar.reset: (w0: str) -> None\n",
      "ex_code_2/Bar.__init__: (x: int) -> None\n",
      "ex_code_1/good: int\n",
      "ex_code_1/fib: (n: int) -> int\n",
      "ex_code_1/Wrapper.foo: (bar: int) -> int\n",
      "ex_code_1/Wrapper.inc: () -> str\n",
      "ex_code_1/int_add: (a: int, b: int) -> str\n",
      "ex_code_1/int_tripple_add: (a: int, b: int, c: int) -> int\n",
      "(updated) ex_code_1/int_add: (a: int, b: int) -> int\n"
     ]
    }
   ],
   "source": [
    "# Use case 1: Run TypeT5 on a given project, taking advantage of existing user \n",
    "# annotations and only make predictions for missing types.\n",
    "\n",
    "project = PythonProject.parse_from_root(proj_root() / \"data/ex_repo\")\n",
    "rollout = await rctx.run_on_project(project, pre_args, decode_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_on_projects: 100%|██████████| 35/35 [00:09<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here\n",
      "==================== /Users/iamariyap/Desktop/sem4/NLP/Final/TypeT5/data/ex_repo ====================\n",
      "\tex_code_2/fib: (n: int) -> int\n",
      "\tex_code_2/foo: (bar: int) -> int\n",
      "\tex_code_2/Bar.__init__: (x: int) -> None\n",
      "\tex_code_2/Bar.reset: (w0: int_add) -> None\n",
      "\tex_code_2/Bar.foo: (z: str) -> str\n",
      "\tex_code_1/fib: (n: int) -> int\n",
      "\tex_code_1/Wrapper.foo: (bar: int) -> int\n",
      "\tex_code_1/Wrapper.inc: () -> int\n",
      "\tex_code_1/int_add: (a: int, b: int) -> str\n",
      "\tex_code_1/int_tripple_add: (a: int, b: int, c: int) -> int\n",
      "\tex_code_2/Bar.z: str\n",
      "\tex_code_2/Bar.w: int_add\n",
      "\tex_code_2/Bar.x: int\n",
      "\tex_code_2/Bar.y: int\n",
      "\tex_code_2/bar: Bar\n",
      "\tex_code_1/good: int\n",
      "\tex_code_1/Wrapper.x_elem: int\n",
      "\tex_code_1/Wrapper.y: int\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use case 2: Run TypeT5 on a test project where all user annotations will be treated as\n",
    "# labels and removed before running the model.\n",
    "\n",
    "print(\"I am here 1\")\n",
    "eval_r = await rctx.evaluate_on_projects([project], pre_args, decode_order)\n",
    "print(\"I am here\")\n",
    "eval_r.print_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_acc:\n",
      "   full_acc: 70.00% (count=10)\n",
      "   full_acc_by_cat:\n",
      "      FuncArg: 100.00% (count=4)\n",
      "      FuncReturn: 0.00% (count=1)\n",
      "      ClassAtribute: 50.00% (count=4)\n",
      "      GlobalVar: 100.00% (count=1)\n",
      "   full_acc_by_simple:\n",
      "      simple: 70.00% (count=10)\n",
      "   full_acc_label_size: 1\n",
      "   full_acc_pred_size: 1\n",
      "   full_acc_ignored_labels: 0\n",
      "full_acc_common:\n",
      "   full_acc_common: 66.67% (count=9)\n",
      "   full_acc_common_by_cat:\n",
      "      FuncArg: 100.00% (count=4)\n",
      "      FuncReturn: 0.00% (count=1)\n",
      "      ClassAtribute: 33.33% (count=3)\n",
      "      GlobalVar: 100.00% (count=1)\n",
      "   full_acc_common_by_simple:\n",
      "      simple: 66.67% (count=9)\n",
      "   full_acc_common_label_size: 1\n",
      "   full_acc_common_pred_size: 1\n",
      "   full_acc_common_ignored_labels: 1\n",
      "full_acc_rare:\n",
      "   full_acc_rare: 100.00% (count=1)\n",
      "   full_acc_rare_by_cat:\n",
      "      FuncArg: 100.00% (count=1)\n",
      "   full_acc_rare_by_simple:\n",
      "      simple: 100.00% (count=1)\n",
      "   full_acc_rare_label_size: 1\n",
      "   full_acc_rare_pred_size: 1\n",
      "   full_acc_rare_ignored_labels: 9\n",
      "acc:\n",
      "   acc: 70.00% (count=10)\n",
      "   acc_by_cat:\n",
      "      FuncArg: 100.00% (count=4)\n",
      "      FuncReturn: 0.00% (count=1)\n",
      "      ClassAtribute: 50.00% (count=4)\n",
      "      GlobalVar: 100.00% (count=1)\n",
      "   acc_by_simple:\n",
      "      simple: 70.00% (count=10)\n",
      "   acc_label_size: 1\n",
      "   acc_pred_size: 1\n",
      "   acc_ignored_labels: 0\n",
      "acc_common:\n",
      "   acc_common: 66.67% (count=9)\n",
      "   acc_common_by_cat:\n",
      "      FuncArg: 100.00% (count=4)\n",
      "      FuncReturn: 0.00% (count=1)\n",
      "      ClassAtribute: 33.33% (count=3)\n",
      "      GlobalVar: 100.00% (count=1)\n",
      "   acc_common_by_simple:\n",
      "      simple: 66.67% (count=9)\n",
      "   acc_common_label_size: 1\n",
      "   acc_common_pred_size: 1\n",
      "   acc_common_ignored_labels: 1\n",
      "acc_rare:\n",
      "   acc_rare: 100.00% (count=1)\n",
      "   acc_rare_by_cat:\n",
      "      FuncArg: 100.00% (count=1)\n",
      "   acc_rare_by_simple:\n",
      "      simple: 100.00% (count=1)\n",
      "   acc_rare_label_size: 1\n",
      "   acc_rare_pred_size: 1\n",
      "   acc_rare_ignored_labels: 9\n",
      "base_acc:\n",
      "   base_acc: 70.00% (count=10)\n",
      "   base_acc_by_cat:\n",
      "      FuncArg: 100.00% (count=4)\n",
      "      FuncReturn: 0.00% (count=1)\n",
      "      ClassAtribute: 50.00% (count=4)\n",
      "      GlobalVar: 100.00% (count=1)\n",
      "   base_acc_ignored_labels: 0\n",
      "base_acc_common:\n",
      "   base_acc_common: 66.67% (count=9)\n",
      "   base_acc_common_by_cat:\n",
      "      FuncArg: 100.00% (count=4)\n",
      "      FuncReturn: 0.00% (count=1)\n",
      "      ClassAtribute: 33.33% (count=3)\n",
      "      GlobalVar: 100.00% (count=1)\n",
      "   base_acc_common_ignored_labels: 1\n",
      "base_acc_rare:\n",
      "   base_acc_rare: 100.00% (count=1)\n",
      "   base_acc_rare_by_cat:\n",
      "      FuncArg: 100.00% (count=1)\n",
      "   base_acc_rare_ignored_labels: 9\n"
     ]
    }
   ],
   "source": [
    "metrics = AccuracyMetric.default_metrics(wrapper.common_type_names)\n",
    "for metric in metrics:\n",
    "    accs = eval_r.error_analysis(None, metric).accuracies\n",
    "    pretty_print_dict({metric.name: accs})\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
